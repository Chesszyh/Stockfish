本节假设已经安装了库，并且可以运行训练器。可以通过运行 `python train.py --help` 来测试。同时，也假设用户已经拥有了他们想要用于训练的训练数据。

# 运行训练器

调用训练器的方式取决于设置和数据。下面给出了一个示例调用，稍后将对每个参数进行详细说明。

```
python3 train.py \
    ./training/data/large_gensfen_multipvdiff_100_d9.binpack \
    ./training/data/large_gensfen_multipvdiff_100_d9.binpack \
    --gpus "0," \
    --threads 4 \
    --num-workers 4 \
    --batch-size 16384 \
    --progress_bar_refresh_rate 20 \
    --random-fen-skipping 3 \
    --features=HalfKAv2_hm^ \
    --lambda=1.0 \
    --max_epochs=400 \
    --default_root_dir ./training/runs/run_0
```

前两个参数分别是训练数据集和验证数据集。数据集以循环方式（无限）读取。训练数据集用于计算梯度并执行反向传播步骤以训练网络。验证数据集用于在训练阶段之间检查网络的性能。这些数据集可能相同，也可能不同。训练（和验证）结果将在很大程度上取决于所选的数据集。

`--gpus` 参数控制用于训练的设备。目前仅支持单 GPU 训练。可以[在此处](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#gpus)找到指定此参数的方式。在上面的示例中，训练器被指示仅使用 ID 为 0 的 GPU。

`--threads` 参数控制 pytorch 将使用的线程数。此参数的最佳值取决于硬件，通常 4 个就足够了。建议在每个硬件上使用 1 到 8 之间的值进行基准测试。

`--num-workers` 参数控制数据加载器将使用的线程数。这些线程在从磁盘读取数据和形成批次之间分配。至少使用 2 个工作线程（一个用于从磁盘读取，一个用于形成批次），因此低于 3 的值无效。建议在每个硬件上使用 1 到 8 之间的值进行基准测试。

在 A100 上的示例基准测试结果：
| 迭代次数/秒 <br> 线程数 >> <br> 工作线程数 VV |
|--------------------------------------------------------|------:|------:|------:|------:|------:|
|                                                      1 | 66.97 | 67.46 | 67.94 | 65.55 | 65.55 |
|                                                      4 | 80.40 | 83.64 | 85.38 | 86.91 | 87.57 |
|                                                      8 | 76.58 | 82.52 | 86.00 | 86.69 | 85.15 |
|                                                     16 | 78.12 |  82.5 | 84.65 | 84.98 | 86.00 |

`--batch_size` 参数控制样本批次的大小。较大的批次需要更多的 GPU 内存，但在高端 GPU 上可能会更快。批次大小和学习率相互依赖。建议使用 16384 的批次大小。

`--progress_bar_refresh_rate` 参数控制训练器产生的控制台输出的刷新率。传递的值是下一次刷新前必须经过的迭代（步骤）次数。在使用高端 GPU 时，较低的值可能会稍微减慢训练速度或导致可见的闪烁。

`--random-fen-skipping` 参数控制训练样本的过滤率。该值越高，读取时跳过样本的概率就越高。较高的值通常会使训练器在更短的时间内看到更多样化的数据，但由于数据加载器的负载增加，可能会减慢训练速度。

`--features` 参数控制用作网络输入的特征集。默认值通常对应于 Stockfish 的主网络。

`--lambda` 参数控制训练器是使用结果（比赛结果）还是分数（评估）作为训练目标。`lambda` 为 1.0 表示纯粹使用分数。`lambda` 为 0.0 表示纯粹使用结果。介于两者之间的值提供两者的按比例混合。

`--max_epochs` 参数指定训练在多少个时期后终止。如果未指定此参数，则必须手动停止训练。

`--default_root_dir` 指定保存检查点和 tensorflow 事件的路径。

## 附加参数

`--no-smart-fen-skipping` 参数禁用数据加载器执行的“智能”样本过滤。众所周知，由于某些原因，网络不能很好地理解具有战术性吃子的局面，对它们进行训练会导致网络变差。这通过“智能局面跳过”得到部分缓解，它会删除最佳着法是吃子的样本。请注意，这不是一个理想的解决方案，但尚未提出更好的解决方案。

`--no-wld-fen-skipping` 参数禁用基于样本评估与结果相关性的随机过滤。研究发现，对于某些数据集（通常涉及 lc0 训练数据），有时跳过评估与最终比赛结果不相关的样本是有益的。对于某些数据集，此过滤可能不是积极的，因此有一种方法可以禁用它。对于某些数据集，它可能会减慢训练速度或需要指定更多的工作线程。禁用它不是一个大的改变，但对于某些数据集来说是可测量的。

## 从现有模型重新启动

### 从 .nnue/.pt 重新启动

要从 .nnue 重新启动，首先需要将其转换为 .pt。这可以通过调用 `python serialize.py --features=<.nnue 文件的特征集> nn.nnue nn.pt` 来完成。

`--resume-from-model` 参数指定要加载为初始训练模型的 .pt 模型的路径。由于它不保存训练状态和优化器状态，因此训练从头开始重新启动，只是从 .pt 模型加载权重和偏差，而不是重新初始化。

训练期间使用的 `--features` 参数必须与 .pt 模型的特征集匹配；它可以选择添加虚拟特征（例如，当 .pt 模型只有 HalfKA 特征时，可以使用 --features=HalfKA^ 进行训练。这在从丢失虚拟特征信息的 .nnue 模型重新启动时很常见）。

这对于使用不同数据集重新训练现有网络或需要更改优化器设置时很有用。

众所周知，由于某些原因，高质量数据集（例如 lc0）在用于重新训练在较低质量数据集（例如在低深度下使用 Stockfish 生成）上训练的网络时，比从零开始在高质量数据集上训练取得更好的结果。

### 从 .ckpt 重新启动

.ckpt 格式包含优化器和训练器状态，因此非常适合在因某种原因暂停训练后恢复训练。

`--resume_from_checkpoint` 参数指定 .ckpt 检查点文件的路径。训练从获取检查点的时期恢复。

# 将网络转换为 .nnue

训练器以 .ckpt 格式输出网络。引擎仅支持 .nnue 格式。要在这两者之间进行转换，可以运行 `python serialize.py --features=<用于训练的特征集> nn.ckpt nn.nnue`。这种转换是有损的，因为 .nnue 格式以量化形式存储权重，删除训练和优化器状态，并将虚拟特征权重合并到真实特征权重中。

# 预期结果

通常，网络需要大约 400 个时期才能成熟，但即使在仅 100 个时期后，它们也可能非常有竞争力。在 400 个时期之后，网络无法改善太多，一个比另一个更好主要是噪音。

要比较不同的架构/训练器设置，可以查看运行之间的验证损失。但请记住，验证损失取决于所使用的数据集和计算损失函数的方式。甚至像增加局面跳过或禁用智能局面跳过之类的事情也会影响验证损失。在这些情况下，有必要使用正在生成的网络进行比赛。

训练中存在一些差异。通常，当以相同的方式但使用不同的随机种子（如果未指定，则种子是随机的）进行多次训练时，生成的网络在强度上会有可测量的差异。在探索代码更改时，需要使用相同的设置进行多次运行才能获得有意义的比较。一组 4 次运行中至少有一次质量相对较好的可能性很大。极少数情况下，网络甚至可能在训练期间损坏，导致比赛强度显着下降，而没有表现出任何其他症状（损失、可视化）。

# 通过 tensorboard 监督训练过程

待办事项：此部分
